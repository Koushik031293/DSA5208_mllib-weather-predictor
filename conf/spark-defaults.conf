# --------------------------------------------------------------------
# Spark runtime configuration for NOAA 51GB MLlib project
# Place this file in conf/  or  $SPARK_HOME/conf/spark-defaults.conf
# --------------------------------------------------------------------

# Application identity
spark.app.name              NOAA-Weather-MLlib
spark.master                local[*]                # or yarn / k8s / spark://<cluster-master>
spark.submit.deployMode     client

# ----------------------------------------------------
# Memory, cores, and parallelism tuning
# ----------------------------------------------------
spark.driver.memory         16g
spark.executor.memory       8g
spark.executor.cores        4
spark.sql.shuffle.partitions        200
spark.default.parallelism          200
spark.sql.files.maxPartitionBytes  134217728         # 128 MB
spark.sql.files.openCostInBytes    67108864          # 64 MB (encourage coalescing)
spark.yarn.appMasterEnv.PYSPARK_PYTHON  ${PYSPARK_PYTHON}
spark.executorEnv.PYSPARK_PYTHON        ${PYSPARK_PYTHON}

# ----------------------------------------------------
# Performance and fault tolerance
# ----------------------------------------------------
spark.serializer            org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max       512m
spark.memory.fraction       0.6
spark.memory.storageFraction 0.4
spark.broadcast.compress    true
spark.rdd.compress          true
spark.shuffle.compress      true
spark.shuffle.spill.compress true
spark.io.compression.codec  snappy
spark.network.timeout       600s
spark.executor.heartbeatInterval 120s

# ----------------------------------------------------
# Logging and event tracking
# ----------------------------------------------------
spark.eventLog.enabled      true
spark.eventLog.dir          file:/tmp/spark-events
spark.ui.showConsoleProgress true
spark.sql.execution.arrow.pyspark.enabled true

# ----------------------------------------------------
# Cluster modes (optional)
# ----------------------------------------------------
# spark.submit.deployMode     cluster
# spark.dynamicAllocation.enabled true
# spark.dynamicAllocation.minExecutors 2
# spark.dynamicAllocation.maxExecutors 16
# spark.dynamicAllocation.initialExecutors 4